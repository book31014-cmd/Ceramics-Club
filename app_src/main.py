import torch
from PIL import Image
import exifread
import glob
import os
from sentence_transformers import SentenceTransformer, util
import sys
from datetime import datetime # æ–°å¢å¼•å…¥ datetime æ¨¡çµ„

# --- 1. è¨­å®š ---
DB_DIR = "èˆŠç…§ç‰‡åº«" # å‘Šè¨´ç¨‹å¼æˆ‘å€‘çš„èˆŠç…§ç‰‡åº«åœ¨å“ªè£¡
# æˆ‘å€‘è®“ç¨‹å¼æº–å‚™å¥½æ¥æ”¶ä¸€å€‹æ–°ç…§ç‰‡çš„åç¨±
if len(sys.argv) < 2:
    print("ä½¿ç”¨æ–¹å¼: python main.py [æ–°ç…§ç‰‡è·¯å¾‘]")
    sys.exit(1)
NEW_PHOTO_PATH = sys.argv[1] # å–å¾—æ‚¨è¼¸å…¥çš„æ–°ç…§ç‰‡åç¨±

MODEL_NAME = "clip-ViT-B-32" # ä½¿ç”¨ AI æ¨¡å‹åç¨±
device = "cuda" if torch.cuda.is_available() else "cpu"

# --- 2. è¼‰å…¥ AI å¤§è…¦ ---
try:
    model = SentenceTransformer(MODEL_NAME, device=device)
    print(f"AI åŠ©æ‰‹å·²å°±ç·’ï¼Œä½¿ç”¨è£ç½®ï¼š{device}")
except Exception as e:
    print(f"è¼‰å…¥ AI å¤§è…¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ–å®‰è£: {e}")
    sys.exit(1)

# --- 3. æº–å‚™èˆŠç…§ç‰‡è¨˜æ†¶ ---
def get_image_features(image_paths):
    # ä½¿ç”¨ try-except ç¢ºä¿åœ–ç‰‡èƒ½æ­£å¸¸æ‰“é–‹
    images = []
    valid_paths = []
    for path in image_paths:
        try:
            # è½‰æ›ç‚º RGB ç¢ºä¿èˆ‡æ¨¡å‹ç›¸å®¹
            images.append(Image.open(path).convert("RGB"))
            valid_paths.append(path)
        except Exception as e:
            print(f"ç„¡æ³•é–‹å•Ÿåœ–ç‰‡ {path}: {e}")
            
    if not images:
        print("èˆŠç…§ç‰‡åº«ä¸­æ²’æœ‰å¯ç”¨çš„åœ–ç‰‡ã€‚")
        sys.exit(1)

    # å°‡åœ–ç‰‡è½‰æ›ç‚º AI èƒ½ç†è§£çš„ç‰¹å¾µå‘é‡
    features = model.encode(images, convert_to_tensor=True, show_progress_bar=False)
    return features, valid_paths

# èåˆå¾Œçš„ get_exif_time å‡½æ•¸ (åŒ…å« EXIF è®€å–åŠæª”æ¡ˆä¿®æ”¹æ™‚é–“å‚™æ´)
def get_exif_time(image_path):
    try:
        with open(image_path, 'rb') as f:
            tags = exifread.process_file(f)
            # å˜—è©¦ç²å–å¤šå€‹å¯èƒ½çš„æ—¥æœŸæ¨™ç±¤
            if 'EXIF DateTimeOriginal' in tags:
                return str(tags['EXIF DateTimeOriginal'])
            elif 'Image DateTime' in tags:
                 return str(tags)
            elif 'DateTime' in tags:
                 return str(tags['DateTime'])
    except Exception as e:
        pass
    
    # å¦‚æœæ‰¾ä¸åˆ° EXIF è³‡è¨Šï¼Œå˜—è©¦è®€å–æª”æ¡ˆçš„ä¿®æ”¹æ™‚é–“ (Fallback Option)
    try:
        m_time_timestamp = os.path.getmtime(image_path)
        # æ ¼å¼åŒ–è¼¸å‡ºä»¥ç¬¦åˆ EXIF çš„æ¨™æº–æ™‚é–“æ ¼å¼
        return datetime.fromtimestamp(m_time_timestamp).strftime('%Y:%m:%d %H:%M:%S')
    except Exception as e:
        pass

    return "æœªçŸ¥æ™‚é–“"


# å–å¾—è³‡æ–™åº«ä¸­çš„æ‰€æœ‰åœ–ç‰‡è·¯å¾‘
db_image_paths = glob.glob(os.path.join(DB_DIR, '*.jpg')) + \
                 glob.glob(os.path.join(DB_DIR, '*.png'))

if not db_image_paths:
    print(f"éŒ¯èª¤: åœ¨ '{DB_DIR}' è³‡æ–™å¤¾ä¸­æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡ã€‚")
    sys.exit(1)

db_features, db_valid_paths = get_image_features(db_image_paths)


# --- 4. æ¯”å°æ–°ç…§ç‰‡ ---
def find_similar_photo(new_photo_path):
    try:
        # è™•ç†æ–°ç…§ç‰‡çš„ç‰¹å¾µ
        new_photo = Image.open(new_photo_path).convert("RGB")
        new_photo_feature = model.encode(new_photo, convert_to_tensor=True)
    except Exception as e:
        print(f"éŒ¯èª¤: ç„¡æ³•è™•ç†æ–°ç…§ç‰‡ '{new_photo_path}': {e}")
        sys.exit(1)


    # è¨ˆç®—ç›¸ä¼¼åº¦åˆ†æ•¸ (é¤˜å¼¦ç›¸ä¼¼åº¦ï¼Œåˆ†æ•¸è¶Šé«˜è¶Šåƒ)
    cos_scores = util.cos_sim(new_photo_feature, db_features)
    
    # --- ä¿®æ­£æ­¤è™•çš„é‚è¼¯ï¼Œé¿å… RuntimeError: a Tensor with 2 elements cannot be converted to Scalar ---
    # ç²å–æœ€é«˜åˆ†æ•¸çš„ç´¢å¼•ï¼ˆå°‡ç´¢å¼•è½‰æ›ç‚ºç´”é‡æ•´æ•¸ï¼‰
    best_match_idx_scalar = torch.argmax(cos_scores).item()
    
    # å¾åˆ†æ•¸çŸ©é™£ä¸­å–å‡ºè©²å–®ä¸€æœ€é«˜åˆ†æ•¸
    # cos_scores.flatten() å°‡ 1xN è½‰ç‚º N å€‹å…ƒç´ çš„å‘é‡
    best_score = cos_scores.flatten()[best_match_idx_scalar].item()
    best_match_path = db_valid_paths[best_match_idx_scalar]
    # ------------------------------------------------------------------------------------

    best_match_time = get_exif_time(best_match_path)

    # å ±å‘Šçµæœ
    print("-" * 40)
    print(f"æ‚¨è¦æ±‚æ¯”å°çš„æ–°ç…§ç‰‡: {os.path.basename(new_photo_path)}")
    print(f"è³‡æ–™åº«ä¸­æœ€ç›¸ä¼¼çš„ç…§ç‰‡: {os.path.basename(best_match_path)}")
    print(f"ç›¸ä¼¼åº¦åˆ†æ•¸ (æ»¿åˆ† 1.0): {best_score:.4f}")
    print(f"é‚£å¼µèˆŠç…§ç‰‡çš„æ‹æ”æ™‚é–“: {best_match_time}")
    print("-" * 40)
    
    if best_score > 0.85: # å¦‚æœç›¸ä¼¼åº¦å¾ˆé«˜ (è¶…é 85%)
        print(f"ğŸ‰ çµè«–: AI èªç‚ºé€™**å¾ˆå¯èƒ½**æ˜¯åŒä¸€ä»¶ä½œå“ï¼æ‚¨ä¸Šæ¬¡æ‹å®ƒæ˜¯åœ¨ {best_match_time}ã€‚")
    else:
        print(f"ğŸ¤” çµè«–: ç›¸ä¼¼åº¦ä¸é«˜ï¼Œå¯èƒ½æ˜¯ä¸€ä»¶å…¨æ–°çš„ä½œå“å–”ï¼")


# --- 5. å•Ÿå‹•æ¯”å° ---
find_similar_photo(NEW_PHOTO_PATH)
